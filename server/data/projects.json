[
  {
    "id": 1,
    "title": "Electron-Photon particle classification with ResNet-15",
    "domain": "astrophysics",
    "description": "Using ResNet-15 architecture to classify electron-photon particles based on their energy signatures and track properties.",
    "fullDescription": "<p>Don't really know what's the love for ResNet-15 here. I mean from what I see on first glance, this model looks like something people created for Super-resolution and last time I checked, model trying to identify whether a particle is an electron or photon isnt really a super-resolution problem but ay, I'm not the boss here.</p>",
    "technologies": [
      "PyTorch",
      "ResNet",
      "High-Energy Physics",
      "TensorFlow",
      "CUDA",
      "Data Augmentation"
    ],
    "results": "Achieved 96% classification accuracy, significantly improving particle identification in LHC experiments and enabling more precise cross-section measurements.",
    "githubUrl": "https://github.com/example/electron-photon-classification",
    "notebookUrl": "https://github.com/example/electron-photon-classification/blob/main/analysis.ipynb",
    "featured": 1,
    "status": "in-progress"
  },
  {
    "id": 2,
    "title": "Event Classification With Masked Transformer Autoencoders",
    "domain": "astrophysics",
    "description": "Developing masked transformer autoencoders for event classification in high-energy physics experiments.",
    "fullDescription": "<p>This project implements masked transformer autoencoder architectures to classify complex events in high-energy physics experiments. By masking portions of the input data during training, the model learns robust feature representations that generalize well to unseen events.</p><p>The architecture combines the strength of transformers for capturing long-range dependencies with the regularization benefits of masking strategies. This approach has proven particularly effective for dealing with the complex, high-dimensional data produced in particle collision experiments.</p>",
    "technologies": [
      "Transformers",
      "PyTorch",
      "High-Energy Physics",
      "Self-Supervised Learning",
      "Masking Strategies",
      "Attention Mechanisms"
    ],
    "results": "Improved event classification accuracy by 17% compared to traditional deep learning approaches, with particular gains in identifying rare physics processes.",
    "githubUrl": "https://github.com/example/masked-transformer-event-classification",
    "notebookUrl": "https://github.com/example/masked-transformer-event-classification/blob/main/analysis.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 3,
    "title": "Super-Resolution and reconstruction of LHC events using GAN's",
    "domain": "astrophysics",
    "description": "Applying Generative Adversarial Networks to enhance resolution and reconstruct detailed event structures from noisy and incomplete Large Hadron Collider data.",
    "fullDescription": "<p>This project explores the application of Generative Adversarial Networks (GANs) to enhance the resolution of detector readings and reconstruct complete event structures from the Large Hadron Collider. The approach allows for improved analysis of particle collision events even when the detector data is noisy or incomplete.</p><p>The GAN architecture consists of a generator network that learns to create high-resolution, complete event representations, and a discriminator network that distinguishes between real and generated events. This adversarial training process results in a model that can produce physically accurate reconstructions while enhancing detail beyond the original detector resolution.</p>",
    "technologies": [
      "GANs",
      "PyTorch",
      "CUDA",
      "ROOT",
      "Scientific Visualization",
      "Particle Physics"
    ],
    "results": "Demonstrated 3x improvement in spatial resolution for jet reconstruction, enabling more precise measurements of particle properties and interactions in high-energy physics experiments.",
    "githubUrl": "https://github.com/example/lhc-super-resolution",
    "notebookUrl": "https://github.com/example/lhc-super-resolution/blob/main/gan_model.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 4,
    "title": "End-to-End event classification with sparse autoencoders",
    "domain": "astrophysics",
    "description": "Using sparse autoencoder architectures to perform end-to-end classification of complex event structures in high-energy physics.",
    "fullDescription": "<p>This project implements sparse autoencoder architectures to perform end-to-end classification of complex event structures in high-energy physics experiments. The approach leverages the power of unsupervised pretraining to learn meaningful representations from unlabeled data, followed by supervised fine-tuning for specific classification tasks.</p><p>By incorporating sparsity constraints into the autoencoder training, the model learns to represent the data using a minimal number of active neurons, leading to more interpretable features that correspond to meaningful physical properties. This approach has proven particularly effective for identifying rare signals amidst abundant background processes.</p>",
    "technologies": [
      "Autoencoders",
      "PyTorch",
      "Sparse Coding",
      "Unsupervised Learning",
      "Transfer Learning",
      "High-Performance Computing"
    ],
    "results": "Achieved 89% accuracy in classifying rare physics processes while reducing computational requirements by 60% compared to conventional deep learning approaches.",
    "githubUrl": "https://github.com/example/sparse-autoencoder-event-classification",
    "notebookUrl": "https://github.com/example/sparse-autoencoder-event-classification/blob/main/analysis.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 5,
    "title": "Diffusion models for fast and accurate simulations of low level LHC experiment data",
    "domain": "astrophysics",
    "description": "Implementing diffusion probabilistic models to generate realistic simulations of particle physics experiments, significantly accelerating the simulation process.",
    "fullDescription": "<p>This project implements diffusion probabilistic models to create fast, accurate simulations of particle physics experiments at the Large Hadron Collider. Traditional Monte Carlo simulations are computationally expensive, and this approach offers orders of magnitude speedup while maintaining physical accuracy.</p><p>The diffusion model gradually converts noise into realistic detector signals through an iterative denoising process. It's trained on high-fidelity simulation data to capture the complex underlying physics processes. The approach incorporates physical constraints to ensure conservation laws are respected in the generated data.</p>",
    "technologies": [
      "Diffusion Models",
      "JAX",
      "Flax",
      "High-Performance Computing",
      "GEANT4",
      "Statistical Physics"
    ],
    "results": "Achieved 500x speedup in simulation time compared to traditional Monte Carlo methods while maintaining 98% accuracy in key physics observables.",
    "githubUrl": "https://github.com/example/diffusion-lhc-sim",
    "notebookUrl": "https://github.com/example/diffusion-lhc-sim/blob/main/model.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 6,
    "title": "CEBRA-Based Data Processing Pipeline for EEG Analysis",
    "domain": "biology",
    "description": "Applying unsupervised learning techniques to identify patterns in gene expression data from cancer patients to discover potential subtypes.",
    "fullDescription": "<p>This project explores the application of unsupervised learning methods to analyze gene expression data from cancer patients. The goal was to identify previously unknown cancer subtypes that might respond differently to treatments or have different prognoses.</p><p>Working with RNA-seq data from The Cancer Genome Atlas (TCGA), I applied dimensionality reduction techniques like t-SNE and UMAP to visualize the high-dimensional gene expression data. This was followed by clustering algorithms including hierarchical clustering, k-means, and DBSCAN to identify potential cancer subtypes.</p><p>The project also included survival analysis to determine whether the identified clusters corresponded to clinically relevant differences in patient outcomes. Additionally, pathway enrichment analysis was performed to understand the biological mechanisms that differentiate the clusters.</p>",
    "technologies": [
      "R",
      "Bioconductor",
      "scikit-learn",
      "UMAP",
      "Clustering",
      "Survival Analysis"
    ],
    "results": "Identified three distinct molecular subtypes in breast cancer samples with significantly different survival rates and treatment responses.",
    "githubUrl": "https://github.com/example/cancer-expression-clustering",
    "notebookUrl": "https://github.com/example/cancer-expression-clustering/blob/main/analysis.ipynb",
    "featured": 1,
    "status": "in-progress"
  },
  {
    "id": 7,
    "title": "Protein Structure Prediction",
    "domain": "biology",
    "description": "Developing a deep learning model inspired by AlphaFold to predict 3D protein structures from amino acid sequences.",
    "fullDescription": "<p>Protein structure prediction is one of the most challenging problems in computational biology. This project implements a simplified version of the AlphaFold approach to predict the three-dimensional structure of proteins from their amino acid sequences.</p><p>I developed a multi-stage pipeline that includes sequence alignment, feature extraction, and a deep neural network architecture combining attention mechanisms and convolutional layers. The model was trained on the PDB database of known protein structures.</p><p>Special attention was given to evaluating the quality of predicted structures using metrics like RMSD (Root Mean Square Deviation) and TM-score (Template Modeling score), which measure the similarity between predicted and experimental structures.</p><p>The project also includes a visualization component that allows users to interactively explore the predicted protein structures.</p>",
    "technologies": [
      "Python",
      "PyTorch",
      "BioPython",
      "Attention Networks",
      "Molecular Visualization",
      "HPC"
    ],
    "results": "Achieved an average RMSD of 4.2Ã… on test proteins, enabling accurate structure prediction for several previously unsolved proteins.",
    "githubUrl": "https://github.com/example/protein-structure-prediction",
    "notebookUrl": "https://github.com/example/protein-structure-prediction/blob/main/model.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 8,
    "title": "Ancient Text Classification",
    "domain": "humanities",
    "description": "Using NLP and machine learning to classify ancient manuscripts by time period, region, and authorship based on linguistic features.",
    "fullDescription": "<p>This project applies natural language processing and machine learning techniques to classify ancient manuscripts based on various attributes including time period, geographical region, and authorship.</p><p>Working with a corpus of digitized ancient texts from different historical periods and regions, I extracted a wide range of linguistic features including vocabulary distributions, syntactic patterns, and stylometric markers. These features were then used to train machine learning models for classification tasks.</p><p>The project faced several challenges related to working with ancient texts, including incomplete documents, spelling variations, and evolving language use over time. I implemented several preprocessing steps to address these challenges, including text normalization, handling of abbreviations, and dealing with lacunae (gaps in texts).</p><p>The classification models were evaluated using cross-validation techniques, with special attention to the interpretability of results to ensure they would be useful for humanities scholars.</p>",
    "technologies": [
      "NLP",
      "BERT",
      "Historical Linguistics",
      "Python",
      "spaCy",
      "Digital Humanities"
    ],
    "results": "Achieved 84% accuracy in dating ancient manuscripts, helping scholars resolve debates about the provenance of several contentious texts.",
    "githubUrl": "https://github.com/example/ancient-text-classification",
    "notebookUrl": "https://github.com/example/ancient-text-classification/blob/main/classification.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 9,
    "title": "ARC-AGI Experiments",
    "domain": "kaggle",
    "description": "Exploring methods to solve the Abstraction and Reasoning Corpus challenge as a pathway to more general artificial intelligence.",
    "fullDescription": "<p>This project tackles the Abstraction and Reasoning Corpus (ARC) challenge, which tests AI systems on their ability to solve novel reasoning tasks with minimal examples. The challenge is designed to evaluate progress toward more general AI capabilities beyond specialized models.</p><p>I developed an approach that combines symbolic reasoning, program synthesis, and neural networks to identify underlying patterns and generate solutions. The system attempts to discover the rules that transform input grids to output grids by testing hypotheses about the transformations involved.</p><p>The work involved creating a domain-specific language for representing transformations, a search algorithm to explore the space of possible programs, and a neural guidance module to prioritize promising directions.</p>",
    "technologies": [
      "Symbolic AI",
      "Program Synthesis",
      "Reinforcement Learning",
      "PyTorch",
      "Graph Neural Networks",
      "Meta-Learning"
    ],
    "results": "Successfully solved 43% of ARC tasks, representing a significant improvement over baseline approaches and providing insights into abstraction capabilities in AI systems.",
    "githubUrl": "https://github.com/example/arc-agi",
    "notebookUrl": "https://github.com/example/arc-agi/blob/main/solver.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 10,
    "title": "Nexar Dashcam Accident Prediction",
    "domain": "kaggle",
    "description": "Developing a real-time system to predict potential traffic accidents from dashcam video feeds, providing early warnings to drivers.",
    "fullDescription": "<p>This project aims to predict potential traffic accidents before they occur by analyzing real-time dashcam video feeds. Using data from the Nexar dashcam challenge, I developed a multi-modal system that combines computer vision, time series analysis, and contextual information to identify dangerous traffic situations.</p><p>The model processes video frames through a 3D CNN architecture to capture temporal patterns in traffic flow and driver behavior. It also incorporates GPS, accelerometer data, and map information to understand the driving context. A recurrent neural network integrates these signals to provide a continuous risk assessment.</p><p>Special attention was given to class imbalance issues, as accidents are rare events compared to normal driving conditions. Techniques including focal loss, data augmentation, and hard negative mining were employed to improve model sensitivity.</p>",
    "technologies": [
      "Computer Vision",
      "3D CNNs",
      "LSTMs",
      "TensorFlow",
      "Multi-modal Learning",
      "Time Series Analysis"
    ],
    "results": "Achieved 87% precision and 83% recall in identifying high-risk situations 3-5 seconds before potential accidents, providing critical time for driver intervention.",
    "githubUrl": "https://github.com/example/dashcam-prediction",
    "notebookUrl": "https://github.com/example/dashcam-prediction/blob/main/model.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 11,
    "title": "Quantum Neural Networks for Classification",
    "domain": "quantum",
    "description": "Implementing quantum neural networks on IBM's quantum computers to solve classification problems with potential quantum advantage.",
    "fullDescription": "<p>This project explores the implementation of quantum neural networks (QNNs) on real quantum hardware provided by IBM Quantum. The goal was to investigate whether these quantum models could offer advantages for certain classification tasks compared to classical neural networks.</p><p>I designed a variational quantum circuit that serves as the core of the QNN, with trainable rotation gates and entangling operations. The model was applied to several benchmark classification datasets, with a focus on problems where quantum correlations might be beneficial.</p><p>The project addressed various challenges in quantum machine learning, including circuit depth limitations on current hardware, noise mitigation strategies, and efficient parameter optimization techniques. Hybrid quantum-classical training approaches were employed to make the best use of both computing paradigms.</p>",
    "technologies": [
      "Qiskit",
      "Quantum Computing",
      "Variational Quantum Circuits",
      "PennyLane",
      "PyTorch",
      "IBM Quantum"
    ],
    "results": "Demonstrated comparable performance to classical models on small datasets while requiring fewer parameters, and identified specific problem structures where quantum approaches show promise for future advantage.",
    "githubUrl": "https://github.com/example/quantum-nn",
    "notebookUrl": "https://github.com/example/quantum-nn/blob/main/qnn_classifier.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 12,
    "title": "Finance Time Series Prediction",
    "domain": "finance",
    "description": "Developing advanced time series forecasting models for financial market prediction with uncertainty quantification.",
    "fullDescription": "<p>This project focuses on developing advanced time series forecasting models for financial market prediction, with a particular emphasis on quantifying prediction uncertainty. Traditional point forecasts are of limited use in financial applications without a measure of confidence.</p><p>I implemented several state-of-the-art probabilistic forecasting approaches, including GARCH variants, Bayesian structural time series, and neural network-based methods such as DeepAR and Temporal Fusion Transformers. These models were trained on historical market data from multiple asset classes.</p><p>A key innovation in this project was the integration of alternative data sources (social media sentiment, macroeconomic indicators, and option-implied volatility) into the forecasting models using attention mechanisms to dynamically weight the importance of different inputs based on market conditions.</p><p>Extensive backtesting was performed using proper scoring rules like the Continuous Ranked Probability Score (CRPS) to evaluate the calibration and sharpness of the probabilistic forecasts.</p>",
    "technologies": [
      "PyTorch",
      "Probabilistic Programming",
      "GARCH",
      "Bayesian Methods",
      "Attention Networks",
      "Alternative Data"
    ],
    "results": "Achieved 24% improvement in the CRPS over baseline methods, with particularly strong performance during periods of market stress when accurate risk forecasts are most valuable.",
    "githubUrl": "https://github.com/example/finance-ts-prediction",
    "notebookUrl": "https://github.com/example/finance-ts-prediction/blob/main/models.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 13,
    "title": "Deep Learning Inference for mass regression",
    "domain": "astrophysics",
    "description": "Using deep neural networks to perform accurate mass regression for particle physics applications, improving precision in collision event analysis.",
    "fullDescription": "<p>This project implements deep neural network architectures to perform accurate mass regression for particle physics applications. In high-energy physics, precisely determining the mass of particles produced in collision events is crucial for discovering new physics phenomena.</p><p>The model processes raw detector data to directly infer the mass of particles, bypassing traditional reconstruction techniques that can introduce systematic biases. By learning from simulated data where the ground truth is known, the network can generalize to real experimental data with high accuracy.</p>",
    "technologies": [
      "PyTorch",
      "Deep Learning",
      "Regression Analysis",
      "Physics-Informed ML",
      "Uncertainty Quantification",
      "Transfer Learning"
    ],
    "results": "Improved mass resolution by 35% compared to traditional template-based methods, enabling more sensitive searches for new particles and interactions.",
    "githubUrl": "https://github.com/example/mass-regression-dl",
    "notebookUrl": "https://github.com/example/mass-regression-dl/blob/main/analysis.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 14,
    "title": "Next generation vision transformers for end to end mass regression",
    "domain": "astrophysics",
    "description": "Implementing advanced vision transformer architectures for end-to-end mass regression in particle physics, improving upon traditional convolutional approaches.",
    "fullDescription": "<p>This project explores the application of next-generation vision transformer architectures for end-to-end mass regression in particle physics. While convolutional neural networks have been the standard approach for image-based tasks in high-energy physics, transformer-based architectures offer potential advantages in capturing global dependencies and handling variable-sized inputs.</p><p>The model was designed to process detector images directly and predict particle masses, bypassing traditional reconstruction steps. Key innovations include physics-aware positional encodings that incorporate detector geometry information and a hierarchical transformer architecture that efficiently processes the high-resolution detector images.</p>",
    "technologies": [
      "Vision Transformers",
      "PyTorch",
      "JAX",
      "Attention Mechanisms",
      "High-Performance Computing",
      "Physics-Informed ML"
    ],
    "results": "Achieved a 28% improvement in mass resolution compared to CNN-based approaches, with particular gains for complex events with multiple overlapping particles.",
    "githubUrl": "https://github.com/example/vision-transformer-mass-regression",
    "notebookUrl": "https://github.com/example/vision-transformer-mass-regression/blob/main/model.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 15,
    "title": "Exploring use-case of Quantum ML algorithms for exoplanet detection",
    "domain": "astrophysics",
    "description": "Investigating potential quantum machine learning approaches for detecting exoplanets from astronomical data, exploring quantum advantage in this domain.",
    "fullDescription": "<p>This project explores the potential applications of quantum machine learning algorithms for detecting exoplanets from astronomical data. With the growing capabilities of quantum computing hardware, there's increasing interest in understanding which scientific problems might benefit from quantum approaches.</p><p>I implemented several quantum-enhanced algorithms, including quantum support vector machines, variational quantum classifiers, and quantum feature maps, to process light curve data from space telescopes like Kepler and TESS. The goal was to identify the characteristic transit signals that indicate the presence of exoplanets.</p><p>The work involved benchmarking these quantum approaches against state-of-the-art classical methods to identify potential quantum advantages in terms of sample complexity, noise resilience, or detection sensitivity. Special attention was given to designing algorithms that could be executed on near-term quantum devices with limited qubit counts and gate fidelities.</p>",
    "technologies": [
      "Qiskit",
      "PennyLane",
      "Quantum Machine Learning",
      "Variational Quantum Circuits",
      "Astronomy",
      "Time Series Analysis"
    ],
    "results": "Demonstrated proof-of-concept quantum advantage in sample efficiency for simplified transit detection problems, identifying promising directions for further quantum algorithm development as hardware capabilities increase.",
    "githubUrl": "https://github.com/example/quantum-exoplanet-detection",
    "notebookUrl": "https://github.com/example/quantum-exoplanet-detection/blob/main/analysis.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 16,
    "title": "Comparing Graph-based and Autoencoder approaches to classify quark-gluon events",
    "domain": "astrophysics",
    "description": "Conducting a comparative study of graph neural networks and autoencoder architectures for quark-gluon jet classification in particle physics.",
    "fullDescription": "<p>This project performs a systematic comparison of graph neural networks and autoencoder architectures for the classification of quark and gluon jets in high-energy physics. Distinguishing between these fundamental particles is a challenging task with important applications in searches for new physics phenomena.</p><p>I implemented several state-of-the-art graph neural network architectures that naturally represent jets as point clouds or graphs of particles, as well as various autoencoder-based approaches that learn compressed representations of jet properties. The models were trained and evaluated on both simulated and real collider data from the Large Hadron Collider.</p><p>The study analyzed the performance of different approaches across various jet energy ranges and detector regions, with particular attention to the physics interpretability of the learned features and the robustness to systematic uncertainties in the training data.</p>",
    "technologies": [
      "Graph Neural Networks",
      "Autoencoders",
      "PyTorch Geometric",
      "Particle Physics",
      "Scientific ML",
      "Point Cloud Processing"
    ],
    "results": "Found that graph-based approaches outperformed autoencoders by 12% in classification accuracy, while also demonstrating better generalization to detector regions not seen during training.",
    "githubUrl": "https://github.com/example/quark-gluon-classification",
    "notebookUrl": "https://github.com/example/quark-gluon-classification/blob/main/comparison.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 17,
    "title": "End-to-End particle collision track reconstruction using GNN's",
    "domain": "astrophysics",
    "description": "Developing graph neural networks to reconstruct particle tracks from detector hits in high-energy physics experiments, improving tracking efficiency.",
    "fullDescription": "<p>This project develops graph neural network architectures to perform end-to-end particle track reconstruction from detector hits in high-energy physics experiments. Track reconstruction is a fundamental task in particle physics that involves connecting the individual energy deposits left by particles as they traverse detector layers.</p><p>The approach formulates the problem as a graph learning task, where detector hits are represented as nodes, and the model learns to predict which hits belong to the same particle trajectory. This end-to-end learning approach offers advantages over traditional algorithmic methods, particularly in high-density collision environments where tracks frequently overlap.</p><p>Special attention was given to incorporating physical constraints (such as the helical nature of charged particle trajectories in magnetic fields) into the model architecture and loss function to ensure physically plausible reconstructions.</p>",
    "technologies": [
      "Graph Neural Networks",
      "PyTorch Geometric",
      "CUDA",
      "High-Performance Computing",
      "Detector Physics",
      "Geometric Deep Learning"
    ],
    "results": "Improved tracking efficiency by 18% in high-density environments compared to classical algorithms, while reducing the computational requirements by a factor of 5.",
    "githubUrl": "https://github.com/example/gnn-track-reconstruction",
    "notebookUrl": "https://github.com/example/gnn-track-reconstruction/blob/main/model.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 18,
    "title": "Foundation models for End-to-End event reconstruction",
    "domain": "astrophysics",
    "description": "Developing large-scale foundation models for comprehensive end-to-end reconstruction of particle physics events, inspired by recent advances in AI foundation models.",
    "fullDescription": "<p>This project explores the development of large-scale foundation models for comprehensive end-to-end reconstruction of particle physics events. Inspired by the success of foundation models in computer vision and natural language processing, this work aims to create versatile base models that can be fine-tuned for various downstream physics tasks.</p><p>The approach involves pretraining large neural network architectures on diverse datasets from multiple experiments using self-supervised learning objectives. These objectives are designed to encourage the model to learn general-purpose representations of detector data that capture the underlying physics processes.</p><p>The foundation model is then fine-tuned for specific tasks such as particle identification, energy calibration, and event classification. By leveraging transfer learning, the model can achieve high performance even for tasks with limited labeled data.</p>",
    "technologies": [
      "Foundation Models",
      "Self-Supervised Learning",
      "Transfer Learning",
      "Distributed Training",
      "Physics-Informed AI",
      "Multi-modal Learning"
    ],
    "results": "Demonstrated successful transfer learning across multiple physics tasks, reducing the amount of task-specific training data needed by up to 70% while maintaining or improving performance.",
    "githubUrl": "https://github.com/example/physics-foundation-models",
    "notebookUrl": "https://github.com/example/physics-foundation-models/blob/main/pretraining.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 19,
    "title": "Graph Transformers for Fast Detector Simulation",
    "domain": "astrophysics",
    "description": "Implementing graph transformer architectures for efficient and accurate simulation of particle detector responses, accelerating physics analyses.",
    "fullDescription": "<p>This project implements graph transformer architectures for fast and accurate simulation of particle detector responses in high-energy physics. Traditional Monte Carlo simulations of detector interactions are computationally expensive, creating a bottleneck for many physics analyses.</p><p>The graph transformer approach represents both the detector geometry and particle properties as nodes and edges in a graph, allowing the model to learn complex interactions through self-attention mechanisms. This architecture effectively captures both local and long-range dependencies that are critical for accurate simulation.</p><p>The model was trained on large datasets of detailed GEANT4 simulations, learning to directly predict detector responses to particle interactions. Particular attention was paid to preserving rare physics behaviors and maintaining physical consistency in the generated outputs.</p>",
    "technologies": [
      "Graph Transformers",
      "PyTorch Geometric",
      "Self-Attention",
      "GEANT4",
      "Physics Simulation",
      "GPU Acceleration"
    ],
    "results": "Achieved 300x speedup compared to traditional simulation methods while maintaining 95% accuracy for key physics observables, enabling previously infeasible large-scale physics studies.",
    "githubUrl": "https://github.com/example/graph-transformer-detector-sim",
    "notebookUrl": "https://github.com/example/graph-transformer-detector-sim/blob/main/model.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 20,
    "title": "Finding gravitational lenses in images using deep-learning approaches",
    "domain": "astrophysics",
    "description": "Developing deep learning models to detect gravitational lensing effects in astronomical images, comparing with physics-informed neural networks.",
    "fullDescription": "<p>This project develops deep learning models to automatically identify gravitational lensing effects in astronomical images. Gravitational lenses, where light from distant galaxies is bent by massive objects along the line of sight, provide valuable information about dark matter distribution and cosmological parameters.</p><p>I implemented several convolutional neural network architectures optimized for this specific detection task, as well as physics-informed neural networks (PINNs) that incorporate gravitational lensing equations into the model architecture. The comparative analysis explored the trade-offs between purely data-driven approaches and those with physics-based inductive biases.</p><p>The models were trained on a combination of simulated lensing images and real observations with confirmed lensing effects. Data augmentation techniques were employed to improve robustness to various observing conditions and telescope-specific artifacts.</p>",
    "technologies": [
      "Computer Vision",
      "CNNs",
      "Physics-Informed Neural Networks",
      "Astronomical Image Processing",
      "TensorFlow",
      "Simulation"
    ],
    "results": "Achieved 93% detection accuracy on test images, successfully identifying 17 new gravitational lens candidates in survey data that were subsequently confirmed by follow-up observations.",
    "githubUrl": "https://github.com/example/gravitational-lens-detection",
    "notebookUrl": "https://github.com/example/gravitational-lens-detection/blob/main/model_comparison.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 21,
    "title": "Upscaling low-resolution images of strong lensing using Super-Resolution algorithms",
    "domain": "astrophysics",
    "description": "Applying super-resolution techniques to enhance low-resolution astronomical images of gravitational lensing phenomena, revealing detailed substructures.",
    "fullDescription": "<p>This project applies state-of-the-art super-resolution techniques to enhance low-resolution astronomical images of strong gravitational lensing. High-quality images of these rare phenomena are crucial for detailed analysis of dark matter distribution and cosmological parameters.</p><p>I implemented and compared several deep learning-based super-resolution approaches, including SRGAN, ESRGAN, and SwinIR, adapting them to the specific challenges of astronomical images such as point spread function modeling and noise characteristics. The models were trained on simulated lensing images with paired low and high-resolution versions.</p><p>Special attention was given to preserving scientifically important features such as faint arcs and multiple images while avoiding the introduction of spurious details that could lead to incorrect scientific conclusions. Validation included both quantitative metrics and expert assessment by astronomers.</p>",
    "technologies": [
      "Super-Resolution",
      "GANs",
      "Vision Transformers",
      "Astronomical Image Processing",
      "PyTorch",
      "Point Spread Function Modeling"
    ],
    "results": "Achieved 4x resolution enhancement with faithful preservation of lensing features, enabling detailed substructure analysis of lensed galaxies previously impossible with direct observations.",
    "githubUrl": "https://github.com/example/lensing-super-resolution",
    "notebookUrl": "https://github.com/example/lensing-super-resolution/blob/main/models.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 22,
    "title": "Deep Graph Anomaly Detection with Contrastive Learning",
    "domain": "astrophysics",
    "description": "Implementing graph-based anomaly detection with contrastive learning to identify rare and unusual events in high-energy physics experiments.",
    "fullDescription": "<p>This project implements graph-based anomaly detection with contrastive learning to identify rare and unusual events in high-energy physics experiments. Finding anomalous collision events is crucial for discovering new particles or interactions that aren't predicted by the Standard Model.</p><p>The approach represents collision events as graphs, where particles are nodes with features like energy and momentum, and edges represent potential interactions. The model learns normal event patterns through self-supervised contrastive learning, without requiring labeled anomalies in the training data.</p><p>By learning to distinguish between augmented versions of the same event versus different events, the model develops a representation space where anomalous events naturally stand out. This approach is particularly valuable for model-independent searches where physicists don't know precisely what new physics might look like.</p>",
    "technologies": [
      "Graph Neural Networks",
      "Contrastive Learning",
      "Anomaly Detection",
      "Self-Supervised Learning",
      "PyTorch",
      "High-Energy Physics"
    ],
    "results": "Successfully identified simulated beyond-Standard-Model physics processes with 4.5 sigma significance, demonstrating sensitivity to a range of potential new physics scenarios without being trained on specific models.",
    "githubUrl": "https://github.com/example/graph-anomaly-physics",
    "notebookUrl": "https://github.com/example/graph-anomaly-physics/blob/main/contrastive_model.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 23,
    "title": "Creating a machine learning pipeline for protoplanetary disks",
    "domain": "astrophysics",
    "description": "Developing an end-to-end machine learning pipeline for analyzing protoplanetary disks using ALMA data, automating feature extraction and classification.",
    "fullDescription": "<p>This project develops an end-to-end machine learning pipeline for analyzing protoplanetary disks using data from the Atacama Large Millimeter/submillimeter Array (ALMA). These disks of gas and dust around young stars are the birthplaces of planets, and their detailed analysis provides insights into planet formation processes.</p><p>The pipeline includes modules for data preprocessing (calibration, cleaning, and standardization of ALMA observations), automated feature extraction (identifying structures like gaps, rings, and spiral arms), and classification of disk types. Deep learning architectures including U-Net for segmentation and CNNs for classification were implemented and optimized for radio astronomy data.</p><p>A particular focus was placed on interpretability, with techniques such as Class Activation Mapping used to highlight which regions of the disk contributed most to classification decisions. This helps astronomers understand the model's reasoning and connect it to physical processes in protoplanetary systems.</p>",
    "technologies": [
      "PyTorch",
      "Radio Astronomy",
      "Computer Vision",
      "U-Net",
      "CASA",
      "Interpretable AI"
    ],
    "results": "Automated the analysis of 200+ protoplanetary disks from the ALMA archive, identifying previously overlooked structural features in 15% of the sample and establishing new correlations between disk properties and stellar host characteristics.",
    "githubUrl": "https://github.com/example/protoplanetary-disk-ml",
    "notebookUrl": "https://github.com/example/protoplanetary-disk-ml/blob/main/pipeline.ipynb",
    "featured": 1,
    "status": "not-started"
  },
  {
    "id": 24,
    "title": "Classification models for different dark matter substructures",
    "domain": "astrophysics",
    "description": "Developing machine learning approaches to classify different types of dark matter substructures in astronomical observations and simulations.",
    "fullDescription": "<p>This project develops machine learning approaches to classify different types of dark matter substructures in both observational data and cosmological simulations. Identifying and characterizing dark matter substructures is crucial for constraining dark matter models and understanding structure formation in the universe.</p><p>I implemented a suite of classification models trained on features extracted from gravitational lensing images, galaxy kinematic data, and simulated dark matter halos. The classifiers were designed to distinguish between predictions of different dark matter theories, such as cold, warm, and self-interacting dark matter, based on their characteristic substructure patterns.</p><p>Transfer learning techniques were employed to bridge between simulation-trained models and real observational data, addressing the sim-to-real gap. Uncertainty quantification was incorporated to account for observational errors and model limitations.</p>",
    "technologies": [
      "XGBoost",
      "Bayesian Neural Networks",
      "Simulation-Based Inference",
      "PyTorch",
      "Astronomical Data Processing",
      "Uncertainty Quantification"
    ],
    "results": "Achieved 85% accuracy in distinguishing between cold and warm dark matter models based on substructure features, providing new constraints on dark matter particle properties from observational data.",
    "githubUrl": "https://github.com/example/dark-matter-classification",
    "notebookUrl": "https://github.com/example/dark-matter-classification/blob/main/analysis.ipynb",
    "featured": 0,
    "status": "not-started"
  },
  {
    "id": 25,
    "title": "Training a Masked Autoencoder on strong lensing images",
    "domain": "astrophysics",
    "description": "Implementing a Masked Autoencoder to learn feature representations of strong gravitational lensing images for improved analysis and detection.",
    "fullDescription": "<p>This project implements a Masked Autoencoder (MAE) approach to learn feature representations of strong gravitational lensing images. By training on samples with no substructures, the model learns a baseline representation that makes anomalous features more detectable.</p><p>The MAE architecture randomly masks portions of input lensing images and trains the model to reconstruct the missing pixels. This self-supervised approach allows learning from large datasets of unlabeled lensing images. After pretraining, the encoder portion of the model can be fine-tuned for downstream tasks such as lens detection, parameter estimation, or anomaly detection.</p><p>Experiments were conducted with various masking strategies, architecture designs, and reconstruction objectives to optimize the learned representations for astrophysical usefulness. The approach was validated on both simulated lensing images and real observations from survey telescopes.</p>",
    "technologies": [
      "Masked Autoencoders",
      "Self-Supervised Learning",
      "Vision Transformers",
      "PyTorch",
      "Astronomical Image Processing",
      "Transfer Learning"
    ],
    "results": "Reduced the amount of labeled data needed for accurate lens parameter estimation by 80%, while also improving sensitivity to subtle substructure features by 35% compared to supervised-only approaches.",
    "githubUrl": "https://github.com/example/lensing-mae",
    "notebookUrl": "https://github.com/example/lensing-mae/blob/main/pretraining.ipynb",
    "featured": 0,
    "status": "not-started"
  }
]
